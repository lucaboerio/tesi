{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3bwPhcHcKp2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torch.autograd.functional import jacobian\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Catena di Markov:\n",
        "\n",
        "*   $\\texttt{entropy}$ --> calcola l'entropia di una sequenza\n",
        "*   $\\texttt{make_entropy_MK}$ --> genera una matrice di transizione per una catena di Markov con una certa entropia\n",
        "*   $\\texttt{sample_MK}$ --> genera una catena di Markov sulla base di una matrice di transizione\n",
        "*   $\\texttt{KL_divergence}$ --> divergenza di Kullback-Leibler\n",
        "*   $\\texttt{Gradino_Markov}$ --> funzione che implementa il cambio di regime nella catena di Markov\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "$\\textit{nessun problema riscontrato}$"
      ],
      "metadata": {
        "id": "5PHAaPCgEoPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(distr, norm=False):\n",
        "    distr = np.array(distr)\n",
        "    min_bin_value = 1.e-12\n",
        "    ind = np.where(distr > min_bin_value)[0]\n",
        "    if norm:\n",
        "        return (-distr[ind] * np.log(distr[ind])).sum() / np.log(distr.shape[0])\n",
        "    else:\n",
        "        return (-distr[ind] * np.log(distr[ind])).sum()"
      ],
      "metadata": {
        "id": "wjGk7fzlIzlE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_entropy_MK(n_bins, target_entropy, norm = True, power=100, tol=0.0001, factor=0.9, max_iter=1e5):\n",
        "    A = np.random.random(size=(n_bins, n_bins))\n",
        "\n",
        "    for k in range(n_bins):\n",
        "        A[k,:] /= A[k,:].sum()\n",
        "\n",
        "    it = 0\n",
        "\n",
        "    while it < max_iter:\n",
        "        lim_distr = np.linalg.matrix_power(A,power)[0,:]\n",
        "        entr = entropy(lim_distr, norm=norm)\n",
        "\n",
        "        if np.abs(entr - target_entropy) < tol:\n",
        "            return A, lim_distr\n",
        "        else:\n",
        "            ind_node = np.random.randint(n_bins)\n",
        "            ind_bin = np.random.randint(n_bins)\n",
        "            A1 = A.copy()\n",
        "            A1[ind_node, ind_bin] *= factor\n",
        "            A1[ind_node,:] /= A1[ind_node,:].sum()\n",
        "            lim_distr1 = np.linalg.matrix_power(A1,power)[0,:]\n",
        "            entr1 = entropy(lim_distr1, norm=norm)\n",
        "            if np.abs(entr1 - target_entropy) > np.abs(entr - target_entropy):\n",
        "                A1 = A.copy()\n",
        "                A1[ind_node, ind_bin] *= 2 - factor\n",
        "                A1[ind_node,:] /= A1[ind_node,:].sum()\n",
        "            A = A1\n",
        "            it += 1\n",
        "\n",
        "print(make_entropy_MK(5,0.2,norm=True,power=100,tol=0.0001,factor=0.9,max_iter=1e6)[1])\n",
        "print(entropy(make_entropy_MK(5,0.2,norm=True,power=100,tol=0.0001,factor=0.9,max_iter=1e6)[1],norm=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKW7I5N7HS7d",
        "outputId": "767b63dc-3297-435c-ac0c-18e94006f16e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.38998986e-02 3.06295356e-04 5.65068161e-03 3.18044358e-03\n",
            " 9.16962681e-01]\n",
            "0.19991023049278947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_MK(A, n_samples, init_node=-1):\n",
        "    n_bins = A.shape[0]\n",
        "    if init_node == -1:\n",
        "        init_node = np.random.randint(n_bins)\n",
        "    samples = []\n",
        "    prev_sample = init_node\n",
        "    for k in range(n_samples):\n",
        "        samples.append(np.random.choice(np.arange(n_bins), p=A[prev_sample,:]))\n",
        "        prev_sample = samples[-1]\n",
        "    return np.array(samples)"
      ],
      "metadata": {
        "id": "elP35LQKQSfe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KL_divergence(distr1, distr2):\n",
        "    distr1 = np.array(distr1)\n",
        "    distr2 = np.array(distr2)\n",
        "    return (distr1 * np.log2(distr1 / distr2)).sum()"
      ],
      "metadata": {
        "id": "j7Owf69SHGue"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "G0vd6T1fkwVQ"
      },
      "outputs": [],
      "source": [
        "def Gradino_Markov(seq_pars):\n",
        "  n_bins = seq_pars['n_bins']\n",
        "  power = seq_pars['power']\n",
        "  initial_entropy = seq_pars['initial_entropy']\n",
        "  middle_entropy = seq_pars['middle_entropy']\n",
        "  Aseq = []\n",
        "  lim_distr_seq = []\n",
        "\n",
        "  A0, lim_distr0 = make_entropy_MK(n_bins, initial_entropy)\n",
        "  At = A0.copy()\n",
        "  lim_distrt = lim_distr0.copy()\n",
        "  Aseq.append(A0)\n",
        "  lim_distr_seq.append(lim_distr0)\n",
        "\n",
        "  A0, lim_distr0 = make_entropy_MK(n_bins, middle_entropy)\n",
        "  Aseq.append(A0)\n",
        "  lim_distr_seq.append(lim_distr0)\n",
        "\n",
        "  subseqs_len = seq_pars['tot_len']\n",
        "  transitions_len = seq_pars['transition_len']\n",
        "  n_subseqs = len(Aseq) # 2, sequenza iniziale e finale\n",
        "\n",
        "  samples = []\n",
        "  A_samples = []\n",
        "  lim_distr_samples = []\n",
        "  entropy_seq = []\n",
        "  init_node = -1\n",
        "  for k in range(n_subseqs):\n",
        "    samples += list(sample_MK(Aseq[k], subseqs_len, init_node=init_node)) #catena mk lunga subseq_len\n",
        "    for j in range(subseqs_len):\n",
        "        A_samples += [Aseq[k]]\n",
        "        lim_distr_samples += [lim_distr_seq[k]]\n",
        "        entropy_seq += [entropy(lim_distr_samples[-1], norm=False)]\n",
        "\n",
        "    #passo in modo graduale da una matrice a un altra tramite tante matrici (50) e ogni volta estraggo uno stato da una di esse\n",
        "    if k < n_subseqs - 1:\n",
        "        B = np.zeros((n_bins, n_bins, transitions_len))\n",
        "        B[:,:,0] = Aseq[k]\n",
        "        B[:,:,-1] = Aseq[k+1]\n",
        "\n",
        "        for i in range(n_bins):\n",
        "            for j in range(n_bins):\n",
        "                B[i,j,:] = np.linspace(Aseq[k][i][j], Aseq[k+1][i][j], transitions_len)\n",
        "\n",
        "        for i in range(transitions_len):\n",
        "            A_samples += [B[:,:,i]]\n",
        "            samples += [sample_MK(A_samples[-1], 1, init_node=samples[-1])[-1]]\n",
        "            lim_distr_samples += [np.linalg.matrix_power(A_samples[-1], power)[0,:]]\n",
        "            entropy_seq += [entropy(lim_distr_samples[-1], norm=False)]\n",
        "\n",
        "    init_node = samples[-1]\n",
        "\n",
        "  samples = np.array(samples)\n",
        "  A_samples = np.array(A_samples)\n",
        "  lim_distr_samples = np.array(lim_distr_samples)\n",
        "\n",
        "  ns_seq_dict = dict()\n",
        "  ns_seq_dict['A'] = A_samples\n",
        "  ns_seq_dict['seq'] = samples\n",
        "  ns_seq_dict['distrs_seq'] = lim_distr_samples\n",
        "  ns_seq_dict['entropy_seq'] = entropy_seq\n",
        "  return ns_seq_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rete neurale di Lyapunov applicata ad una catena di Markov\n",
        "\n",
        "*   $\\texttt{class FeedForward}$ --> classe per una semplice rete feed forward\n",
        "*   ciclo di training per massimizzare l'esponente di Lyapunov\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "$\\textit{per alcuni valori del numero di neuroni nei layer della rete il calcolo dello jacobiano fallisce,}$\n",
        "$\\textit{in particolare quando il numero dei neuroni in entrata e uscita Ã¨ maggiore di quello dell' hidden layer}$\n"
      ],
      "metadata": {
        "id": "eaPzqbLiIeiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of a neural network\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.Tanh = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.Tanh(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 20\n",
        "hidden_size = 20\n",
        "output_size = input_size\n",
        "num_steps = 50\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "mk = 0\n",
        "# Model and initial condition\n",
        "if mk :\n",
        "  mtx = make_entropy_MK(input_size, 0.3, True, 100, 1e-03,0.9, 1e5)[0]\n",
        "  chain = sample_MK(mtx, input_size)\n",
        "  model = FeedForward(input_size, hidden_size, output_size)\n",
        "  initial_condition = torch.zeros((1, input_size))\n",
        "  initial_condition[0, :] =  torch.tensor(chain)\n",
        "else:\n",
        "  model = FeedForward(input_size, hidden_size, output_size)\n",
        "  initial_condition = torch.rand((1, input_size))\n",
        "\n",
        "\n",
        "# Lyapunov exponent plot\n",
        "lyapunov_exponent_plot = np.zeros(epochs)\n",
        "\n",
        "# Input trajectory\n",
        "input_trajectory_list = []\n",
        "lyapunovs_list_mean = torch.zeros(epochs,input_size)\n",
        "\n",
        "# Choose optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "\n",
        "    # Initial condition\n",
        "    input = initial_condition.clone().requires_grad_(True)\n",
        "\n",
        "    # Lyapunov exponent lists\n",
        "    eigenvalues_sum = torch.zeros(num_steps, requires_grad=True)\n",
        "\n",
        "    eigenvalues_prod = torch.ones(num_steps, requires_grad=True)\n",
        "\n",
        "    lyapunovs_sum = torch.zeros(num_steps, requires_grad=True)\n",
        "\n",
        "    lyapunov_max = torch.zeros(num_steps, requires_grad=True)\n",
        "\n",
        "    lyapunovs_list = torch.zeros(input_size)\n",
        "    for i in range(num_steps):\n",
        "        # Compute Jacobian matrix for the original trajectory\n",
        "        jacobian_matrix = jacobian(model, input, create_graph=True)\n",
        "        jacobian_matrix = torch.reshape(jacobian_matrix.clone(), (input_size, input_size))\n",
        "\n",
        "        # Calculate Eigenvalues\n",
        "        if torch.isnan(jacobian_matrix).any() or torch.isinf(jacobian_matrix).any():\n",
        "            # Handle NaN or Inf values in the Jacobian matrix\n",
        "            print(\"Jacobian matrix contains NaN or Inf values. Skipping update.\")\n",
        "            continue\n",
        "\n",
        "        eigenvalues = torch.linalg.eigvals(jacobian_matrix)\n",
        "\n",
        "\n",
        "        # Update the Lyapunov sum\n",
        "        eigenvalues_sum = torch.cat((eigenvalues_sum, torch.abs(torch.sum(eigenvalues)).view(1)))\n",
        "\n",
        "        eigenvalues_prod = torch.cat((eigenvalues_prod, torch.prod(torch.abs(eigenvalues)).view(1)))\n",
        "\n",
        "        lyapunovs = torch.log(torch.abs(eigenvalues))\n",
        "\n",
        "        lyapunov_max = torch.cat((lyapunov_max, torch.max(lyapunovs).view(1)))\n",
        "\n",
        "        lyapunovs_sum = torch.cat((lyapunovs_sum, torch.sum(lyapunovs).view(1)))\n",
        "\n",
        "        lyapunovs_list+=(lyapunovs)/num_steps\n",
        "\n",
        "        # Save the input vector to the trajectory\n",
        "        input_trajectory_list.append(input.detach().numpy().squeeze())\n",
        "\n",
        "        # Update the trajectory\n",
        "        input = model(input)\n",
        "\n",
        "    # Averages of eigenvalues and Lyapunov exponents\n",
        "\n",
        "    eigenvalues_sum_mean = torch.mean(eigenvalues_sum) # Mean over steps of the sum of the eigenvalues of the jacobian\n",
        "\n",
        "    eigenvalues_prod_mean = torch.mean(eigenvalues_prod) # mean over steps of the product od the eigenvalues of the jacobian\n",
        "\n",
        "    lyapunov_exponent = torch.mean(lyapunov_max) # Mean over the logarithm of the absolute value of the biggest eigenvalue (in module) of the jacobian (Biggest Lyapunov Exponent)\n",
        "\n",
        "    lyapunov_sum_mean = torch.mean(lyapunovs_sum) # Mean over the sum of the lyapunov exponents\n",
        "\n",
        "    lyapunovs_list_mean[epoch]=(lyapunovs_list) # Mean values of the lyapunov exponents for every epoch\n",
        "\n",
        "    # alpha an beta are the parameters that regulate the loss\n",
        "    alpha = + 0.0\n",
        "    beta = + 1.0\n",
        "\n",
        "    # Define the loss\n",
        "    loss =  alpha * torch.abs(lyapunov_exponent) + beta * (-lyapunov_sum_mean) / initial_condition.size(1)  # Normalize by the number of dimensions\n",
        "\n",
        "    # Learning Step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "        # Store  Lyapunov exponent\n",
        "    lyapunov_exponent_plot[epoch] = lyapunov_exponent.item() / initial_condition.size(1)\n",
        "\n",
        "\n",
        "    # plot the Lyapunov exponent over time\n",
        "    if epoch > 0:\n",
        "      clear_output(wait=True)\n",
        "      plt.figure(figsize=(12, 6))\n",
        "      plt.axhline(y = 0.0, color = 'r', linestyle = '-')  # specifying horizontal line type\n",
        "      plt.plot(lyapunov_exponent_plot, label='Lyapunov Exponent')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.ylabel('Lyapunov Exponent')\n",
        "      plt.title('Training Progress')\n",
        "      plt.legend()\n",
        "      plt.xlim((0, epoch))\n",
        "      plt.show()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Lyapunov Loss: {lyapunov_exponent.item()}')\n",
        "        print(f'\\nlyapunov_sum_mean: {lyapunov_sum_mean}')\n",
        "\n",
        "# Check the final Lyapunov exponent\n",
        "print(\"Final Lyapunov Exponent:\", lyapunov_exponent_plot[-1])\n",
        "print(\"Final Eigenvalues sum:\", lyapunov_sum_mean)\n",
        "# Convert input trajectory list to a numpy array\n",
        "input_trajectory_array = np.array(input_trajectory_list)"
      ],
      "metadata": {
        "id": "1lZvKnVhIqWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c348f1a1-e961-49a9-9050-afac1b6c0a3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Lyapunov Exponent: 0.001557844877243042\n",
            "Final Eigenvalues sum: tensor(-0.0901, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fase di training\n",
        "\n",
        "* $\\texttt{class FeedForward1}$ --> semplice rete con un embedding layer iniziale e layer lineari\n",
        "* $\\texttt{class FeedForward2}$ --> rete semplice con layer lineari\n",
        "* $\\texttt{training_loop}$ --> funzione che implementa un ciclo di training\n",
        "* $\\texttt{training_pars}$ --> dizionario che contiene tutti i parametri per li training\n",
        "* $\\texttt{lyapunov_pars}$ --> dizionario che contiene tutti i paramentri per gli esponenti di Lyapunov\n",
        "* $\\texttt{seq_pars}$ --> dizionario che contiene tutti i paramentri per generare le sequenze di training\n",
        "\n",
        "---\n",
        "\n",
        "$\\textit{il problema piÃ¹ rilevante riguardava il calcolo dello jacobiano: la funzione} \\: \\texttt{jacobian()} \\: \\textit{prende come argomenti una funzione e il suo input, restituendo come risultato un tensore che ha le dimensioni dell'output e dell'input della funzione moltiplicate.}$\n",
        "$\\textit{Per esempio, se l'output ha dimensione (10, 10) e l'input (10), il tensore avrÃ  dimensione (10x10x10), e se volessimo avere da jacobian() una matrice quadrata }$\n",
        "$\\textit{che le dimensioni del vettore di input (come effettivamente vogliamo), non ci sarebbe soluzione (apparentemente).} $\n",
        "$\\textit{Ora, in}\\:\\texttt{FeedForward1}\\:\\textit{il layer di embedding aggiunge una dimensione all'input, facendoci ricadere nell'esempio di cui sopra.}$\n",
        "$\\textit{Se non ci sono soluzione, l'unica cosa possibile Ã¨ o combiare al rete(vedi}\\:\\texttt{FeedForward2}\\:\\textit{), o tagliare tutte le altre dimensioni che l'embedding layer restituisce in modo da dare un output compatibile}$\n",
        "$\\textit{(ma in questo caso quanto avrebbe senso conservare questo layer se uno poi lo utilizza in maniera \"impropria\"?)}$\n",
        "\n",
        "\n",
        "$\\textit{Oltre a questo, mettendo la rete con il layer di embedding, lo jabiano viene totalmente nullo, facendo fallire tutto il training.}$"
      ],
      "metadata": {
        "id": "XRPcXy_5g6Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(FeedForward1, self).__init__()\n",
        "    self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.act = nn.Tanh()\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "    self.emb = nn.Embedding(input_size, hidden_size)\n",
        "    self.soft = nn.Softmax(0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.long()         #serve solo per il summary\n",
        "    x = self.emb(x)\n",
        "    x = self.act(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.fc2(x)\n",
        "    x = x[0, :]\n",
        "    x = self.soft(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "28cRDwatjC5o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(FeedForward2, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.act = nn.Tanh()\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "    self.soft = nn.Softmax(0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.soft(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "5NNlfIvHmiiL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FeedForward2(10, 100, 10)\n",
        "summary(model, (1, 10))\n",
        "model = FeedForward1(10, 100, 10)\n",
        "summary(model, (1, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ib1OkFniQ0",
        "outputId": "2346e2e0-0c34-4b76-dda5-9a99b982f6b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 100]           1,100\n",
            "              Tanh-2               [-1, 1, 100]               0\n",
            "            Linear-3                [-1, 1, 10]           1,010\n",
            "           Softmax-4                [-1, 1, 10]               0\n",
            "================================================================\n",
            "Total params: 2,110\n",
            "Trainable params: 2,110\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.01\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         Embedding-1           [-1, 1, 10, 100]           1,000\n",
            "              Tanh-2           [-1, 1, 10, 100]               0\n",
            "            Linear-3           [-1, 1, 10, 100]          10,100\n",
            "              Tanh-4           [-1, 1, 10, 100]               0\n",
            "            Linear-5            [-1, 1, 10, 10]           1,010\n",
            "           Softmax-6               [-1, 10, 10]               0\n",
            "================================================================\n",
            "Total params: 12,110\n",
            "Trainable params: 12,110\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.08\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(seq, training_pars, lyapunov_pars):\n",
        "\n",
        "  input_size = training_pars['input_size']\n",
        "  hidden_size = training_pars['hidden_size']\n",
        "  output_size = input_size\n",
        "  lr = training_pars['learning_rate']\n",
        "  seq_length = input_size\n",
        "  batch_size = training_pars['batch_size']\n",
        "\n",
        "  alpha = lyapunov_pars['alpha']\n",
        "  beta = lyapunov_pars['beta']\n",
        "  num_steps = lyapunov_pars['num_steps']\n",
        "\n",
        "\n",
        "  model = FeedForward2(input_size, hidden_size, output_size)\n",
        "  if training_pars['optimizer'] == 'adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  if training_pars['optimizer'] == 'sgd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  if training_pars['loss_func'] == 'CrossEntropy':\n",
        "    loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  for step in range(0, len(seq) - 1, seq_length * batch_size):\n",
        "    loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    model.train()\n",
        "    for b in range(batch_size):\n",
        "      fr = step + seq_length * b\n",
        "      to = fr + seq_length + 1\n",
        "      subseq = seq[fr:to]\n",
        "\n",
        "      inp = torch.Tensor(subseq[:-1])              #\n",
        "      target = torch.LongTensor([subseq[-1]])      #la modeifica al ciclo originale dovrebbe essere questa ma Ã¨ da controllare bene\n",
        "\n",
        "      out = model(inp)\n",
        "\n",
        "      #parte sull'esponente di Lyapunov\n",
        "      input = inp.clone().requires_grad_(True)\n",
        "      lyapunovs_sum = torch.zeros(num_steps, requires_grad=True)\n",
        "      lyapunov_max = torch.zeros(num_steps, requires_grad=True)\n",
        "\n",
        "      for i in range(num_steps):\n",
        "        jacobian_matrix = jacobian(model, input, create_graph=True)\n",
        "        jacobian_matrix = torch.reshape(jacobian_matrix.clone(), (input_size, input_size))\n",
        "\n",
        "        if torch.isnan(jacobian_matrix).any() or torch.isinf(jacobian_matrix).any():\n",
        "            # Handle NaN or Inf values in the Jacobian matrix\n",
        "            print(\"Jacobian matrix contains NaN or Inf values. Skipping update.\")\n",
        "            break\n",
        "\n",
        "        eigenvalues = torch.linalg.eigvals(jacobian_matrix)\n",
        "        lyapunovs = torch.log(torch.abs(eigenvalues))\n",
        "        lyapunov_max = torch.cat((lyapunov_max, torch.max(lyapunovs).view(1)))\n",
        "        lyapunovs_sum = torch.cat((lyapunovs_sum, torch.sum(lyapunovs).view(1)))\n",
        "\n",
        "        input = model(input)\n",
        "\n",
        "      lyapunov_exponent = torch.mean(lyapunov_max)\n",
        "      lyapunov_sum_mean = torch.mean(lyapunovs_sum)\n",
        "      #print(lyapunov_exponent)\n",
        "\n",
        "\n",
        "      loss += loss_func(out.reshape(1, input_size), target) + alpha * torch.abs(lyapunov_exponent) + beta * (-lyapunov_sum_mean) / input.size(0)\n",
        "\n",
        "    loss /= batch_size\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss.item())"
      ],
      "metadata": {
        "id": "5SMb402vVezU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_pars = dict()\n",
        "training_pars['input_size'] = 10\n",
        "training_pars['hidden_size'] = 10\n",
        "training_pars['optimizer'] = 'adam'\n",
        "training_pars['learning_rate'] = 0.0005\n",
        "training_pars['loss_func'] = 'CrossEntropy'\n",
        "training_pars['batch_size'] = 3\n",
        "\n",
        "lyapunov_pars = dict()\n",
        "lyapunov_pars['num_steps'] = 50\n",
        "lyapunov_pars['alpha'] = 0.0\n",
        "lyapunov_pars['beta'] = 0.01\n",
        "\n",
        "seq_pars = dict()\n",
        "seq_pars['power'] = 20\n",
        "seq_pars['n_bins'] = 10                  # deve essere uguale all'input size\n",
        "seq_pars['initial_entropy'] = 0.2\n",
        "seq_pars['middle_entropy'] = 0.3\n",
        "seq_pars['tot_len'] = 5000\n",
        "seq_pars['transition_len'] = 50\n",
        "\n",
        "ns_seq_dict = Gradino_Markov(seq_pars)"
      ],
      "metadata": {
        "id": "DZVFbfLGtH6v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(ns_seq_dict['seq'], training_pars, lyapunov_pars)"
      ],
      "metadata": {
        "id": "P851PM5WTxWE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07ea8d6d-5134-4156-b2f1-7aaf0df10688"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3850, grad_fn=<DivBackward0>)\n",
            "tensor(2.3832, grad_fn=<DivBackward0>)\n",
            "tensor(2.3836, grad_fn=<DivBackward0>)\n",
            "tensor(2.3834, grad_fn=<DivBackward0>)\n",
            "tensor(2.3791, grad_fn=<DivBackward0>)\n",
            "tensor(2.3664, grad_fn=<DivBackward0>)\n",
            "tensor(2.3813, grad_fn=<DivBackward0>)\n",
            "tensor(2.3755, grad_fn=<DivBackward0>)\n",
            "tensor(2.3767, grad_fn=<DivBackward0>)\n",
            "tensor(2.3783, grad_fn=<DivBackward0>)\n",
            "tensor(2.3759, grad_fn=<DivBackward0>)\n",
            "tensor(2.3639, grad_fn=<DivBackward0>)\n",
            "tensor(2.3513, grad_fn=<DivBackward0>)\n",
            "tensor(2.3631, grad_fn=<DivBackward0>)\n",
            "tensor(2.3466, grad_fn=<DivBackward0>)\n",
            "tensor(2.3517, grad_fn=<DivBackward0>)\n",
            "tensor(2.3723, grad_fn=<DivBackward0>)\n",
            "tensor(2.3701, grad_fn=<DivBackward0>)\n",
            "tensor(2.3703, grad_fn=<DivBackward0>)\n",
            "tensor(2.3696, grad_fn=<DivBackward0>)\n",
            "tensor(2.3564, grad_fn=<DivBackward0>)\n",
            "tensor(2.3587, grad_fn=<DivBackward0>)\n",
            "tensor(2.3560, grad_fn=<DivBackward0>)\n",
            "tensor(2.3567, grad_fn=<DivBackward0>)\n",
            "tensor(2.3567, grad_fn=<DivBackward0>)\n",
            "tensor(2.3656, grad_fn=<DivBackward0>)\n",
            "tensor(2.3643, grad_fn=<DivBackward0>)\n",
            "tensor(2.3557, grad_fn=<DivBackward0>)\n",
            "tensor(2.3535, grad_fn=<DivBackward0>)\n",
            "tensor(2.3592, grad_fn=<DivBackward0>)\n",
            "tensor(2.3581, grad_fn=<DivBackward0>)\n",
            "tensor(2.3526, grad_fn=<DivBackward0>)\n",
            "tensor(2.3404, grad_fn=<DivBackward0>)\n",
            "tensor(2.3479, grad_fn=<DivBackward0>)\n",
            "tensor(2.3577, grad_fn=<DivBackward0>)\n",
            "tensor(2.3408, grad_fn=<DivBackward0>)\n",
            "tensor(2.3480, grad_fn=<DivBackward0>)\n",
            "tensor(2.3503, grad_fn=<DivBackward0>)\n",
            "tensor(2.3443, grad_fn=<DivBackward0>)\n",
            "tensor(2.3519, grad_fn=<DivBackward0>)\n",
            "tensor(2.3433, grad_fn=<DivBackward0>)\n",
            "tensor(2.3513, grad_fn=<DivBackward0>)\n",
            "tensor(2.3426, grad_fn=<DivBackward0>)\n",
            "tensor(2.3445, grad_fn=<DivBackward0>)\n",
            "tensor(2.3373, grad_fn=<DivBackward0>)\n",
            "tensor(2.3382, grad_fn=<DivBackward0>)\n",
            "tensor(2.3370, grad_fn=<DivBackward0>)\n",
            "tensor(2.3366, grad_fn=<DivBackward0>)\n",
            "tensor(2.3332, grad_fn=<DivBackward0>)\n",
            "tensor(2.3366, grad_fn=<DivBackward0>)\n",
            "tensor(2.3275, grad_fn=<DivBackward0>)\n",
            "tensor(2.3254, grad_fn=<DivBackward0>)\n",
            "tensor(2.3240, grad_fn=<DivBackward0>)\n",
            "tensor(2.3311, grad_fn=<DivBackward0>)\n",
            "tensor(2.3207, grad_fn=<DivBackward0>)\n",
            "tensor(2.3166, grad_fn=<DivBackward0>)\n",
            "tensor(2.3179, grad_fn=<DivBackward0>)\n",
            "tensor(2.3120, grad_fn=<DivBackward0>)\n",
            "tensor(2.3095, grad_fn=<DivBackward0>)\n",
            "tensor(2.3061, grad_fn=<DivBackward0>)\n",
            "tensor(2.3160, grad_fn=<DivBackward0>)\n",
            "tensor(2.3291, grad_fn=<DivBackward0>)\n",
            "tensor(2.3129, grad_fn=<DivBackward0>)\n",
            "tensor(2.3095, grad_fn=<DivBackward0>)\n",
            "tensor(2.2923, grad_fn=<DivBackward0>)\n",
            "tensor(2.2930, grad_fn=<DivBackward0>)\n",
            "tensor(2.3042, grad_fn=<DivBackward0>)\n",
            "tensor(2.3056, grad_fn=<DivBackward0>)\n",
            "tensor(2.2830, grad_fn=<DivBackward0>)\n",
            "tensor(2.2791, grad_fn=<DivBackward0>)\n",
            "tensor(2.2726, grad_fn=<DivBackward0>)\n",
            "tensor(2.2709, grad_fn=<DivBackward0>)\n",
            "tensor(2.2930, grad_fn=<DivBackward0>)\n",
            "tensor(2.2635, grad_fn=<DivBackward0>)\n",
            "tensor(2.3147, grad_fn=<DivBackward0>)\n",
            "tensor(2.2496, grad_fn=<DivBackward0>)\n",
            "tensor(2.2892, grad_fn=<DivBackward0>)\n",
            "tensor(2.2473, grad_fn=<DivBackward0>)\n",
            "tensor(2.3183, grad_fn=<DivBackward0>)\n",
            "tensor(2.2812, grad_fn=<DivBackward0>)\n",
            "tensor(2.2789, grad_fn=<DivBackward0>)\n",
            "tensor(2.2664, grad_fn=<DivBackward0>)\n",
            "tensor(2.2706, grad_fn=<DivBackward0>)\n",
            "tensor(2.2286, grad_fn=<DivBackward0>)\n",
            "tensor(2.2570, grad_fn=<DivBackward0>)\n",
            "tensor(2.2201, grad_fn=<DivBackward0>)\n",
            "tensor(2.2207, grad_fn=<DivBackward0>)\n",
            "tensor(2.2132, grad_fn=<DivBackward0>)\n",
            "tensor(2.2245, grad_fn=<DivBackward0>)\n",
            "tensor(2.2959, grad_fn=<DivBackward0>)\n",
            "tensor(2.2498, grad_fn=<DivBackward0>)\n",
            "tensor(2.2024, grad_fn=<DivBackward0>)\n",
            "tensor(2.2005, grad_fn=<DivBackward0>)\n",
            "tensor(2.1866, grad_fn=<DivBackward0>)\n",
            "tensor(2.1873, grad_fn=<DivBackward0>)\n",
            "tensor(2.2382, grad_fn=<DivBackward0>)\n",
            "tensor(2.1803, grad_fn=<DivBackward0>)\n",
            "tensor(2.1736, grad_fn=<DivBackward0>)\n",
            "tensor(2.2477, grad_fn=<DivBackward0>)\n",
            "tensor(2.1724, grad_fn=<DivBackward0>)\n",
            "tensor(2.1641, grad_fn=<DivBackward0>)\n",
            "tensor(2.2227, grad_fn=<DivBackward0>)\n",
            "tensor(2.1577, grad_fn=<DivBackward0>)\n",
            "tensor(2.2242, grad_fn=<DivBackward0>)\n",
            "tensor(2.1480, grad_fn=<DivBackward0>)\n",
            "tensor(2.2116, grad_fn=<DivBackward0>)\n",
            "tensor(2.1612, grad_fn=<DivBackward0>)\n",
            "tensor(2.2108, grad_fn=<DivBackward0>)\n",
            "tensor(2.2049, grad_fn=<DivBackward0>)\n",
            "tensor(2.1311, grad_fn=<DivBackward0>)\n",
            "tensor(2.1291, grad_fn=<DivBackward0>)\n",
            "tensor(2.1260, grad_fn=<DivBackward0>)\n",
            "tensor(2.1197, grad_fn=<DivBackward0>)\n",
            "tensor(2.1931, grad_fn=<DivBackward0>)\n",
            "tensor(2.1124, grad_fn=<DivBackward0>)\n",
            "tensor(2.1075, grad_fn=<DivBackward0>)\n",
            "tensor(2.1119, grad_fn=<DivBackward0>)\n",
            "tensor(2.1855, grad_fn=<DivBackward0>)\n",
            "tensor(2.1824, grad_fn=<DivBackward0>)\n",
            "tensor(2.1791, grad_fn=<DivBackward0>)\n",
            "tensor(2.1767, grad_fn=<DivBackward0>)\n",
            "tensor(2.0948, grad_fn=<DivBackward0>)\n",
            "tensor(2.0825, grad_fn=<DivBackward0>)\n",
            "tensor(2.0797, grad_fn=<DivBackward0>)\n",
            "tensor(2.0761, grad_fn=<DivBackward0>)\n",
            "tensor(2.1658, grad_fn=<DivBackward0>)\n",
            "tensor(2.1635, grad_fn=<DivBackward0>)\n",
            "tensor(2.0639, grad_fn=<DivBackward0>)\n",
            "tensor(2.1595, grad_fn=<DivBackward0>)\n",
            "tensor(2.1636, grad_fn=<DivBackward0>)\n",
            "tensor(2.0542, grad_fn=<DivBackward0>)\n",
            "tensor(2.0647, grad_fn=<DivBackward0>)\n",
            "tensor(2.0465, grad_fn=<DivBackward0>)\n",
            "tensor(2.0439, grad_fn=<DivBackward0>)\n",
            "tensor(2.0387, grad_fn=<DivBackward0>)\n",
            "tensor(2.0351, grad_fn=<DivBackward0>)\n",
            "tensor(2.0351, grad_fn=<DivBackward0>)\n",
            "tensor(2.0259, grad_fn=<DivBackward0>)\n",
            "tensor(2.1347, grad_fn=<DivBackward0>)\n",
            "tensor(2.0185, grad_fn=<DivBackward0>)\n",
            "tensor(2.1287, grad_fn=<DivBackward0>)\n",
            "tensor(2.0091, grad_fn=<DivBackward0>)\n",
            "tensor(2.0076, grad_fn=<DivBackward0>)\n",
            "tensor(2.0021, grad_fn=<DivBackward0>)\n",
            "tensor(1.9992, grad_fn=<DivBackward0>)\n",
            "tensor(1.9940, grad_fn=<DivBackward0>)\n",
            "tensor(1.9898, grad_fn=<DivBackward0>)\n",
            "tensor(1.9880, grad_fn=<DivBackward0>)\n",
            "tensor(2.1086, grad_fn=<DivBackward0>)\n",
            "tensor(1.9793, grad_fn=<DivBackward0>)\n",
            "tensor(1.9760, grad_fn=<DivBackward0>)\n",
            "tensor(2.1035, grad_fn=<DivBackward0>)\n",
            "tensor(1.9709, grad_fn=<DivBackward0>)\n",
            "tensor(1.9792, grad_fn=<DivBackward0>)\n",
            "tensor(2.2330, grad_fn=<DivBackward0>)\n",
            "tensor(1.9578, grad_fn=<DivBackward0>)\n",
            "tensor(1.9583, grad_fn=<DivBackward0>)\n",
            "tensor(2.0899, grad_fn=<DivBackward0>)\n",
            "tensor(2.0925, grad_fn=<DivBackward0>)\n",
            "tensor(2.0885, grad_fn=<DivBackward0>)\n",
            "tensor(1.9418, grad_fn=<DivBackward0>)\n",
            "tensor(1.9390, grad_fn=<DivBackward0>)\n",
            "tensor(1.9523, grad_fn=<DivBackward0>)\n",
            "tensor(1.9334, grad_fn=<DivBackward0>)\n",
            "tensor(1.9271, grad_fn=<DivBackward0>)\n",
            "tensor(1.9249, grad_fn=<DivBackward0>)\n",
            "tensor(1.9384, grad_fn=<DivBackward0>)\n",
            "tensor(2.0837, grad_fn=<DivBackward0>)\n",
            "tensor(2.4072, grad_fn=<DivBackward0>)\n",
            "tensor(2.4065, grad_fn=<DivBackward0>)\n",
            "tensor(2.4077, grad_fn=<DivBackward0>)\n",
            "tensor(2.3801, grad_fn=<DivBackward0>)\n",
            "tensor(2.4086, grad_fn=<DivBackward0>)\n",
            "tensor(2.3814, grad_fn=<DivBackward0>)\n",
            "tensor(2.3936, grad_fn=<DivBackward0>)\n",
            "tensor(2.3951, grad_fn=<DivBackward0>)\n",
            "tensor(2.3942, grad_fn=<DivBackward0>)\n",
            "tensor(2.3935, grad_fn=<DivBackward0>)\n",
            "tensor(2.4073, grad_fn=<DivBackward0>)\n",
            "tensor(2.4082, grad_fn=<DivBackward0>)\n",
            "tensor(2.3958, grad_fn=<DivBackward0>)\n",
            "tensor(2.4053, grad_fn=<DivBackward0>)\n",
            "tensor(2.3819, grad_fn=<DivBackward0>)\n",
            "tensor(2.3878, grad_fn=<DivBackward0>)\n",
            "tensor(2.3926, grad_fn=<DivBackward0>)\n",
            "tensor(2.3953, grad_fn=<DivBackward0>)\n",
            "tensor(2.3935, grad_fn=<DivBackward0>)\n",
            "tensor(2.3881, grad_fn=<DivBackward0>)\n",
            "tensor(2.3875, grad_fn=<DivBackward0>)\n",
            "tensor(2.4075, grad_fn=<DivBackward0>)\n",
            "tensor(2.3794, grad_fn=<DivBackward0>)\n",
            "tensor(2.3910, grad_fn=<DivBackward0>)\n",
            "tensor(2.3758, grad_fn=<DivBackward0>)\n",
            "tensor(2.3815, grad_fn=<DivBackward0>)\n",
            "tensor(2.4048, grad_fn=<DivBackward0>)\n",
            "tensor(2.3914, grad_fn=<DivBackward0>)\n",
            "tensor(2.3904, grad_fn=<DivBackward0>)\n",
            "tensor(2.3882, grad_fn=<DivBackward0>)\n",
            "tensor(2.3976, grad_fn=<DivBackward0>)\n",
            "tensor(2.4021, grad_fn=<DivBackward0>)\n",
            "tensor(2.4037, grad_fn=<DivBackward0>)\n",
            "tensor(2.3749, grad_fn=<DivBackward0>)\n",
            "tensor(2.3870, grad_fn=<DivBackward0>)\n",
            "tensor(2.3662, grad_fn=<DivBackward0>)\n",
            "tensor(2.3829, grad_fn=<DivBackward0>)\n",
            "tensor(2.3607, grad_fn=<DivBackward0>)\n",
            "tensor(2.3800, grad_fn=<DivBackward0>)\n",
            "tensor(2.3842, grad_fn=<DivBackward0>)\n",
            "tensor(2.3732, grad_fn=<DivBackward0>)\n",
            "tensor(2.3818, grad_fn=<DivBackward0>)\n",
            "tensor(2.3698, grad_fn=<DivBackward0>)\n",
            "tensor(2.3956, grad_fn=<DivBackward0>)\n",
            "tensor(2.3842, grad_fn=<DivBackward0>)\n",
            "tensor(2.3888, grad_fn=<DivBackward0>)\n",
            "tensor(2.3945, grad_fn=<DivBackward0>)\n",
            "tensor(2.3822, grad_fn=<DivBackward0>)\n",
            "tensor(2.3969, grad_fn=<DivBackward0>)\n",
            "tensor(2.3947, grad_fn=<DivBackward0>)\n",
            "tensor(2.3953, grad_fn=<DivBackward0>)\n",
            "tensor(2.3814, grad_fn=<DivBackward0>)\n",
            "tensor(2.3960, grad_fn=<DivBackward0>)\n",
            "tensor(2.3981, grad_fn=<DivBackward0>)\n",
            "tensor(2.3807, grad_fn=<DivBackward0>)\n",
            "tensor(2.3917, grad_fn=<DivBackward0>)\n",
            "tensor(2.3661, grad_fn=<DivBackward0>)\n",
            "tensor(2.3609, grad_fn=<DivBackward0>)\n",
            "tensor(2.3899, grad_fn=<DivBackward0>)\n",
            "tensor(2.3837, grad_fn=<DivBackward0>)\n",
            "tensor(2.3512, grad_fn=<DivBackward0>)\n",
            "tensor(2.3682, grad_fn=<DivBackward0>)\n",
            "tensor(2.3721, grad_fn=<DivBackward0>)\n",
            "tensor(2.3746, grad_fn=<DivBackward0>)\n",
            "tensor(2.3765, grad_fn=<DivBackward0>)\n",
            "tensor(2.3780, grad_fn=<DivBackward0>)\n",
            "tensor(2.3617, grad_fn=<DivBackward0>)\n",
            "tensor(2.3880, grad_fn=<DivBackward0>)\n",
            "tensor(2.3702, grad_fn=<DivBackward0>)\n",
            "tensor(2.3492, grad_fn=<DivBackward0>)\n",
            "tensor(2.3572, grad_fn=<DivBackward0>)\n",
            "tensor(2.3537, grad_fn=<DivBackward0>)\n",
            "tensor(2.3823, grad_fn=<DivBackward0>)\n",
            "tensor(2.2266, grad_fn=<DivBackward0>)\n",
            "tensor(2.3827, grad_fn=<DivBackward0>)\n",
            "tensor(2.3585, grad_fn=<DivBackward0>)\n",
            "tensor(2.3792, grad_fn=<DivBackward0>)\n",
            "tensor(2.3370, grad_fn=<DivBackward0>)\n",
            "tensor(2.3688, grad_fn=<DivBackward0>)\n",
            "tensor(2.3559, grad_fn=<DivBackward0>)\n",
            "tensor(2.3640, grad_fn=<DivBackward0>)\n",
            "tensor(2.3470, grad_fn=<DivBackward0>)\n",
            "tensor(2.3722, grad_fn=<DivBackward0>)\n",
            "tensor(2.3546, grad_fn=<DivBackward0>)\n",
            "tensor(2.2563, grad_fn=<DivBackward0>)\n",
            "tensor(2.3507, grad_fn=<DivBackward0>)\n",
            "tensor(2.3622, grad_fn=<DivBackward0>)\n",
            "tensor(2.3553, grad_fn=<DivBackward0>)\n",
            "tensor(2.3501, grad_fn=<DivBackward0>)\n",
            "tensor(2.3644, grad_fn=<DivBackward0>)\n",
            "tensor(2.3353, grad_fn=<DivBackward0>)\n",
            "tensor(2.3276, grad_fn=<DivBackward0>)\n",
            "tensor(2.3419, grad_fn=<DivBackward0>)\n",
            "tensor(2.3195, grad_fn=<DivBackward0>)\n",
            "tensor(2.3592, grad_fn=<DivBackward0>)\n",
            "tensor(2.3322, grad_fn=<DivBackward0>)\n",
            "tensor(2.3564, grad_fn=<DivBackward0>)\n",
            "tensor(2.3525, grad_fn=<DivBackward0>)\n",
            "tensor(2.3049, grad_fn=<DivBackward0>)\n",
            "tensor(2.3352, grad_fn=<DivBackward0>)\n",
            "tensor(2.3263, grad_fn=<DivBackward0>)\n",
            "tensor(2.3187, grad_fn=<DivBackward0>)\n",
            "tensor(2.2636, grad_fn=<DivBackward0>)\n",
            "tensor(2.3030, grad_fn=<DivBackward0>)\n",
            "tensor(2.3399, grad_fn=<DivBackward0>)\n",
            "tensor(2.3385, grad_fn=<DivBackward0>)\n",
            "tensor(2.2964, grad_fn=<DivBackward0>)\n",
            "tensor(2.2653, grad_fn=<DivBackward0>)\n",
            "tensor(2.3169, grad_fn=<DivBackward0>)\n",
            "tensor(2.2862, grad_fn=<DivBackward0>)\n",
            "tensor(2.2880, grad_fn=<DivBackward0>)\n",
            "tensor(2.2075, grad_fn=<DivBackward0>)\n",
            "tensor(2.2820, grad_fn=<DivBackward0>)\n",
            "tensor(2.2957, grad_fn=<DivBackward0>)\n",
            "tensor(2.2919, grad_fn=<DivBackward0>)\n",
            "tensor(2.2863, grad_fn=<DivBackward0>)\n",
            "tensor(2.3028, grad_fn=<DivBackward0>)\n",
            "tensor(2.2469, grad_fn=<DivBackward0>)\n",
            "tensor(2.3186, grad_fn=<DivBackward0>)\n",
            "tensor(2.2324, grad_fn=<DivBackward0>)\n",
            "tensor(2.3017, grad_fn=<DivBackward0>)\n",
            "tensor(2.2780, grad_fn=<DivBackward0>)\n",
            "tensor(2.2299, grad_fn=<DivBackward0>)\n",
            "tensor(2.2443, grad_fn=<DivBackward0>)\n",
            "tensor(2.2376, grad_fn=<DivBackward0>)\n",
            "tensor(2.2460, grad_fn=<DivBackward0>)\n",
            "tensor(2.2738, grad_fn=<DivBackward0>)\n",
            "tensor(2.2243, grad_fn=<DivBackward0>)\n",
            "tensor(2.2526, grad_fn=<DivBackward0>)\n",
            "tensor(2.1698, grad_fn=<DivBackward0>)\n",
            "tensor(2.1822, grad_fn=<DivBackward0>)\n",
            "tensor(2.1776, grad_fn=<DivBackward0>)\n",
            "tensor(2.2415, grad_fn=<DivBackward0>)\n",
            "tensor(2.2150, grad_fn=<DivBackward0>)\n",
            "tensor(2.1600, grad_fn=<DivBackward0>)\n",
            "tensor(2.2070, grad_fn=<DivBackward0>)\n",
            "tensor(2.2546, grad_fn=<DivBackward0>)\n",
            "tensor(2.1929, grad_fn=<DivBackward0>)\n",
            "tensor(2.1628, grad_fn=<DivBackward0>)\n",
            "tensor(2.1885, grad_fn=<DivBackward0>)\n",
            "tensor(2.1168, grad_fn=<DivBackward0>)\n",
            "tensor(2.2095, grad_fn=<DivBackward0>)\n",
            "tensor(2.1011, grad_fn=<DivBackward0>)\n",
            "tensor(2.2416, grad_fn=<DivBackward0>)\n",
            "tensor(2.3261, grad_fn=<DivBackward0>)\n",
            "tensor(2.3229, grad_fn=<DivBackward0>)\n",
            "tensor(2.0860, grad_fn=<DivBackward0>)\n",
            "tensor(2.1694, grad_fn=<DivBackward0>)\n",
            "tensor(2.2302, grad_fn=<DivBackward0>)\n",
            "tensor(2.2325, grad_fn=<DivBackward0>)\n",
            "tensor(2.1801, grad_fn=<DivBackward0>)\n",
            "tensor(2.2335, grad_fn=<DivBackward0>)\n",
            "tensor(2.1389, grad_fn=<DivBackward0>)\n",
            "tensor(2.0722, grad_fn=<DivBackward0>)\n",
            "tensor(2.0697, grad_fn=<DivBackward0>)\n",
            "tensor(2.0550, grad_fn=<DivBackward0>)\n",
            "tensor(2.2260, grad_fn=<DivBackward0>)\n",
            "tensor(2.0321, grad_fn=<DivBackward0>)\n",
            "tensor(2.1247, grad_fn=<DivBackward0>)\n",
            "tensor(2.1223, grad_fn=<DivBackward0>)\n",
            "tensor(2.1314, grad_fn=<DivBackward0>)\n",
            "tensor(2.0191, grad_fn=<DivBackward0>)\n",
            "tensor(2.1246, grad_fn=<DivBackward0>)\n",
            "tensor(2.0109, grad_fn=<DivBackward0>)\n",
            "tensor(2.1214, grad_fn=<DivBackward0>)\n",
            "tensor(2.0078, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x9 and 10x10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-43026af74cbe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_seq_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyapunov_pars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-fde08264ecda>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(seq, training_pars, lyapunov_pars)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#la modeifica al ciclo originale dovrebbe essere questa ma Ã¨ da controllare bene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0;31m#parte sull'esponente di Lyapunov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-46fd5a3aced7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x9 and 10x10)"
          ]
        }
      ]
    }
  ]
}